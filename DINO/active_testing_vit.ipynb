{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76d861b-3c87-4936-9440-9eb48f568bf8",
   "metadata": {},
   "source": [
    "## Test different sklearn model on estimating loss\n",
    "\n",
    "The inputs and annotation data from MLP_model_demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc885734-6ff9-4e29-804c-09d85c862085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sas20048/anaconda/envs/at_det/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import copy\n",
    "import sklearn\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.special import softmax\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca115a-0e2a-468b-9441-377fb3c0d341",
   "metadata": {},
   "source": [
    "## Active Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fe56318-ae16-4aff-b4c5-f5448c26aa19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LURE_weights_for_risk_estimator(weights, N):\n",
    "    M = weights.size\n",
    "    if M < N:\n",
    "        m = np.arange(1, M+1)\n",
    "        v = (\n",
    "            1\n",
    "            + (N-M)/(N-m) * (\n",
    "                    1 / ((N-m+1) * weights)\n",
    "                    - 1\n",
    "                    )\n",
    "            )\n",
    "    else:\n",
    "        v = 1\n",
    "\n",
    "    return v\n",
    "\n",
    "def acquire(expected_loss_inputs, samples_num):\n",
    "    assert samples_num <= expected_loss_inputs.size\n",
    "    expected_loss = np.copy(expected_loss_inputs)\n",
    "    # Log-lik can be negative.\n",
    "    # Make all values positive.\n",
    "    if (expected_loss < 0).sum() > 0:\n",
    "        expected_loss += np.abs(expected_loss.min())\n",
    "    \n",
    "    if np.any(np.isnan(expected_loss)):\n",
    "        logging.warning(\n",
    "            'Found NaN values in expected loss, replacing with 0.')\n",
    "        logging.info(f'{expected_loss}')\n",
    "        expected_loss = np.nan_to_num(expected_loss, nan=0)\n",
    "    pick_sample_idxs = np.zeros((samples_num), dtype = int)\n",
    "    idx_array = np.arange(expected_loss.size)\n",
    "    weights = np.zeros((samples_num), dtype = np.single)\n",
    "    uniform_clip_val = 0.2\n",
    "    for i in range(samples_num):\n",
    "        expected_loss /= expected_loss.sum()\n",
    "        # clip all values less than 10 percent of uniform propability\n",
    "        expected_loss = np.maximum(uniform_clip_val * 1/expected_loss.size, expected_loss)\n",
    "        expected_loss /= expected_loss.sum()\n",
    "        sample = np.random.multinomial(1, expected_loss)\n",
    "        cur_idx = np.where(sample)[0][0]\n",
    "        pick_sample_idxs[i] = idx_array[cur_idx]\n",
    "        weights[i] = expected_loss[cur_idx]\n",
    "        selected_mask = np.ones((expected_loss.size), dtype=bool)\n",
    "        selected_mask[cur_idx] = False\n",
    "        expected_loss = expected_loss[selected_mask]\n",
    "        idx_array = idx_array[selected_mask]\n",
    "    return pick_sample_idxs, weights\n",
    "\n",
    "def get_expected_loss(inputs, model):\n",
    "    expected_loss = model.predict(inputs)\n",
    "    return expected_loss\n",
    "\n",
    "def run_one_approximate_risk_estimator(true_losses, expected_losses, seed, samples_num):\n",
    "    # torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    pick_sample_idxs, weights = acquire(expected_losses, samples_num)\n",
    "    risk_estimator_weights = LURE_weights_for_risk_estimator(weights, expected_losses.size)\n",
    "    sampled_true_losses = true_losses[pick_sample_idxs]\n",
    "\n",
    "    loss_risk = (sampled_true_losses * risk_estimator_weights).mean()\n",
    "    return loss_risk\n",
    "\n",
    "def write_one_results(path, json_data):\n",
    "    with open(path, \"w\") as outfile:\n",
    "        json.dump(json_data, outfile)\n",
    "\n",
    "def read_one_results(path):\n",
    "    with open(path, \"r\") as outfile:\n",
    "        data = json.load(outfile)\n",
    "    return data\n",
    "\n",
    "def np_read(file):\n",
    "    with open(file, \"rb\") as outfile:\n",
    "        data = np.load(outfile)\n",
    "    return data\n",
    "def np_write(data, file):\n",
    "    with open(file, \"wb\") as outfile:\n",
    "        np.save(outfile, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff496e11-38f4-4956-82f1-b94cbff44a76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result_json_path = \"./results/MPL_loss_compare/\"\n",
    "# sample_size_set = [50, 100, 150, 200, 250, 500, 750, 1000, 1500, 2000, 3000]\n",
    "# random_seed_set = [4519, 9524, 5901, 1028, 6382, 5383, 5095, 7635,  890,  608]\n",
    "# def active_testing(file_path, true_losses, expected_losses, active_test_type):\n",
    "#     json_object = {}\n",
    "#     for sample_size in sample_size_set:\n",
    "#         for seed in random_seed_set:\n",
    "#             result = {\"active_test_type\": active_test_type, \"sample_size\": sample_size}\n",
    "#             loss_risk = run_one_approximate_risk_estimator(true_losses, expected_losses, seed, sample_size)\n",
    "#             result[\"loss\"] = loss_risk\n",
    "#             json_object[len(json_object)] = result\n",
    "#     with open(file_path, \"w\") as outfile:\n",
    "#         json.dump(json_object, outfile)\n",
    "\n",
    "result_json_path = \"./results/active_test_image_level/\"\n",
    "sample_size_set = np.linspace(50, 1000, 96).astype(int).tolist()\n",
    "random_seed_set = [4519, 9524, 5901]\n",
    "def active_testing(file_path, true_losses, expected_losses, active_test_type):\n",
    "    json_object = {}\n",
    "    for seed in random_seed_set:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        pick_sample_idxs, weights = acquire(expected_losses, sample_size_set[-1])\n",
    "        for sample_size in sample_size_set:\n",
    "            result = {\"active_test_type\": active_test_type, \"sample_size\": sample_size}\n",
    "            risk_estimator_weights = LURE_weights_for_risk_estimator(weights[:sample_size], expected_losses.size)\n",
    "            sampled_true_losses = true_losses[pick_sample_idxs[:sample_size]]\n",
    "            loss_risk = (sampled_true_losses * risk_estimator_weights).mean()\n",
    "            result[\"loss\"] = loss_risk\n",
    "            json_object[len(json_object)] = result\n",
    "    with open(file_path, \"w\") as outfile:\n",
    "        json.dump(json_object, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "567924dd-3761-4d1c-a19b-4dc3064f9e83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.091053703334183e-05,\n",
       " 4.05604875087738,\n",
       " 0.00010378965816926211,\n",
       " 4.621575117111206)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_path = \"./data/5_scale_31/\"\n",
    "train_data_path = model_data_path + \"train/pre_data/\"\n",
    "test_data_path = model_data_path + \"val/pre_data/\"\n",
    "with open(train_data_path + \"train_annotations.npy\", 'rb') as outfile:\n",
    "    tran_Y = np.load(outfile)\n",
    "\n",
    "with open(test_data_path + \"val_annotations.npy\", 'rb') as outfile:\n",
    "    test_Y = np.load(outfile)\n",
    "tran_Y.min(), tran_Y.max(), test_Y.min(), test_Y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbbb972f-af97-48d3-b1d8-668bf60e2cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_list = np.arange(10000, 40001, 5000)\n",
    "# train_step = 5000\n",
    "for train_step in step_list:\n",
    "    val_estimated_loss = np.array(read_one_results(f\"../../ViT-pytorch/output/ViT-feature-det-ordinal-image_losses_{train_step}.json\")['losses'])\n",
    "    file_path = result_json_path + f\"ViT_runs_{train_step}.json\"\n",
    "    active_testing(file_path, test_Y, val_estimated_loss, \"ViT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fafa841-45b9-4728-8271-543625924a8b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "033f3cc8-cd70-4e11-b278-8f3e28e4830b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data_path = \"./data/5_scale_31/\"\n",
    "train_data_path = model_data_path + \"train/pre_data/\"\n",
    "test_data_path = model_data_path + \"val/pre_data/\"\n",
    "with open(train_data_path + \"train_inputs.npy\", 'rb') as outfile:\n",
    "    train_X = np.load(outfile)\n",
    "train_X = train_X.reshape((train_X.shape[0], -1))\n",
    "with open(train_data_path + \"train_annotations.npy\", 'rb') as outfile:\n",
    "    tran_Y = np.load(outfile)\n",
    "with open(test_data_path + \"val_inputs.npy\", 'rb') as outfile:\n",
    "    test_X = np.load(outfile)\n",
    "test_X = test_X.reshape((test_X.shape[0], -1))\n",
    "with open(test_data_path + \"val_annotations.npy\", 'rb') as outfile:\n",
    "    test_Y = np.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8de912c-e76b-48c7-9cc7-46bc977a050f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 900, 95)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_path = \"./data/5_scale_31/\"\n",
    "train_data_path = model_data_path + \"train/pre_data/\"\n",
    "test_data_path = model_data_path + \"val/pre_data/\"\n",
    "with open(train_data_path + \"train_inputs.npy\", 'rb') as outfile:\n",
    "    train_X = np.load(outfile)\n",
    "\n",
    "store_path = model_data_path + \"train/feature/\"\n",
    "for i in range(train_X.shape[0]):\n",
    "    data = copy.deepcopy(train_X[i])\n",
    "    data[:,:-4] = softmax(data[:,:-4], axis=1)\n",
    "    np_write(data, store_path + f\"{i}.npy\")\n",
    "    if i % 1000==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b93ec3e-6b78-4f78-b1f8-e8dcd1f8fe09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 900, 95)\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "with open(test_data_path + \"val_inputs.npy\", 'rb') as outfile:\n",
    "    test_X = np.load(outfile)\n",
    "print(test_X.shape)\n",
    "\n",
    "store_path = model_data_path + \"val/feature/\"\n",
    "for i in range(test_X.shape[0]):\n",
    "    data = copy.deepcopy(test_X[i])\n",
    "    data[:,:-4] = softmax(data[:,:-4], axis=1)\n",
    "    np_write(data, store_path + f\"{i}.npy\")\n",
    "    if i % 1000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd5003-cd80-46b8-aaaf-f3f8e0541caa",
   "metadata": {},
   "source": [
    "## Random Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee97735f-3e17-4350-b27a-9d00c81dc712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_one_random_sample_risk_estimator(true_losses, seed, samples_num):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    perm = np.random.permutation(true_losses.size)\n",
    "    pick_sample_idxs = perm[:samples_num]\n",
    "    sampled_true_losses = true_losses[pick_sample_idxs]\n",
    "    return sampled_true_losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee08f99b-3894-48ba-bf37-4492777e4f67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = result_json_path + \"random_sample_R50_31_10_runs.json\"\n",
    "json_object = {}\n",
    "for sample_size in sample_size_set:\n",
    "    for seed in random_seed_set:\n",
    "        result = {\"active_test_type\": \"random sample\", \"sample_size\": sample_size}\n",
    "        loss_risk = run_one_random_sample_risk_estimator(test_Y, seed, sample_size)\n",
    "        result[\"loss\"] = loss_risk\n",
    "        json_object[len(json_object)] = result\n",
    "with open(file_path, \"w\") as outfile:\n",
    "    json.dump(json_object, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99efd3a8-c681-4414-b206-6a671ac3ac9b",
   "metadata": {},
   "source": [
    "## Whole data set risk estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf1ba2ff-8a8b-40ca-bca1-c27efc0e333b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_whole_data_set_risk_estimator(true_losses):\n",
    "    return true_losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccbe7de3-48d0-454c-a978-ef529e528da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = result_json_path + \"None_R50_31.json\"\n",
    "result = {\"active_test_type\": \"None\", \"sample_size\": test_Y.shape[0]}\n",
    "result[\"loss\"] = get_whole_data_set_risk_estimator(test_Y)\n",
    "json_object = {}\n",
    "json_object[0] = result\n",
    "with open(file_path, \"w\") as outfile:\n",
    "    json.dump(json_object, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cfeb5c-e125-4fe6-b722-fac285bc92fe",
   "metadata": {},
   "source": [
    "## ASE\n",
    "extimated loss from active_test_demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43345f09-981e-4f94-aa12-acf844889eb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = read_one_results(\"./results/loss_analysis/\" + \"image_based_ASE.json\")\n",
    "ase_expected_loss = np.array(results[\"estimated loss\"])\n",
    "true_losses = test_Y\n",
    "file_path = result_json_path + \"ASE_R50_31_10_runs.json\"\n",
    "active_testing(file_path, true_losses, ase_expected_loss, \"ASE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605d431-3f53-44ba-a55f-43a0e8b3603e",
   "metadata": {},
   "source": [
    "## Ensemble Gradient Boosting\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2563ab90-a927-4aa4-b436-daceb1eb7993",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(loss='absolute_error', random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb_reg = GradientBoostingRegressor(random_state=0, loss='absolute_error')\n",
    "gb_reg.fit(train_X[:1000], tran_Y[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45475fdd-65cc-40a1-9c67-ac5cc89afb80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16718003])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_reg.predict(test_X[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "897af597-106a-4344-9a51-031fc99d2bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10270405057616716"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_reg.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80777582-1dd6-4f81-96d8-3e3951a7a90c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_losses = test_Y\n",
    "expected_losses = get_expected_loss(test_X, gb_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd8ebd50-14b7-4125-b8df-6ad1a8fdb650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = result_json_path + \"EGB_R50_31_10_runs.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"EGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c2ac98-4d29-4374-91ae-0af6cf38be44",
   "metadata": {},
   "source": [
    "## AdaBoost Regressor\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c42c00b5-da11-4643-9b53-e970fd18c671",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "abr_reg = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "abr_reg.fit(train_X[:1000], tran_Y[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f098bc3-5bf2-4235-aa36-69719e924651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4134521])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abr_reg.predict(test_X[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0aa34ebf-6535-48bf-b0a2-1c75084162ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09421608247547097"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abr_reg.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "989414cc-ed4b-44b0-a56c-e07d4bb5fda5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_losses = test_Y\n",
    "expected_losses = get_expected_loss(test_X, abr_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "492c6444-8aba-42fa-aeae-766139ecdc5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = result_json_path + \"ABR_R50_31_10_runs.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ABR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f63edfa-887a-4e38-91f9-7defbf1eb73c",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59b62f60-fe4c-4b9d-9995-bbcd5a014a69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([0.001, 0.01 , 0.1  , 1.   ]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "redge_reg = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\n",
    "# redge_reg.fit(train_X[:10000], tran_Y[:10000])\n",
    "redge_reg.fit(train_X, tran_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae010108-f8fd-43b6-8fb5-9abd175b68a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4727245391840673"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redge_reg.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b3d5448-6d45-4071-b49f-0df51596e573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_losses = get_expected_loss(test_X, redge_reg)\n",
    "# np_write(expected_losses, result_json_path + \"RidgeReg_estimated_losses.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6359c6b-6eaa-4881-8178-6f459543e188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_losses = test_Y\n",
    "expected_losses = get_expected_loss(test_X, redge_reg)\n",
    "file_path = result_json_path + \"RedgeReg_R50_31_10_runs_1.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"RR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3bcd74e-f11d-464d-9862-beb9b74b2022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# true_losses = test_Y\n",
    "# expected_losses = get_expected_loss(test_X, redge_reg)\n",
    "# loss_analysis_path = \"./results/loss_analysis/\" + \"image_based_regde_regression.json\"\n",
    "# json_object = {\"true loss\": true_losses.tolist(), \"estimated loss\": expected_losses.tolist()}\n",
    "# write_one_results(loss_analysis_path, json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df2fc0f-5dc7-43ad-a4a3-061f9fb4f6b8",
   "metadata": {},
   "source": [
    "## Isotonic Regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.isotonic.IsotonicRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd181af-0952-4943-958d-0dae24a728b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "redge_reg_X = redge_reg.predict(train_X[5000:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d617e6a2-09ac-4547-b86f-8510dfb97a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iso_reg = IsotonicRegression(y_min = tran_Y[5000:10000].min(), y_max = tran_Y[5000:10000].max(), out_of_bounds='clip')\n",
    "iso_reg.fit(redge_reg_X, tran_Y[5000:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4fab17-e1e3-44fc-94ed-e8d01f802ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "redge_reg_test_X = redge_reg.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb845adf-eb70-43c5-966b-9242e04f5b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_losses = test_Y\n",
    "expected_losses = get_expected_loss(redge_reg_test_X, iso_reg)\n",
    "file_path = result_json_path + \"IsReg_R50_31_10_runs.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"IS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383df15-d60b-42f4-9fcd-e86c2f17a11e",
   "metadata": {},
   "source": [
    "## Random Sample with image level but set the threshold for box level, also use image-level loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3239b804-8ea7-4ef5-998d-f9d28af7f2d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from util.slconfig import SLConfig\n",
    "from datasets import build_dataset\n",
    "model_config_path = \"config/DINO/DINO_5scale.py\"\n",
    "args = SLConfig.fromfile(model_config_path) \n",
    "args.dataset_file = 'coco'\n",
    "args.coco_path = \"../coco/\" # the path of coco\n",
    "args.fix_size = False\n",
    "\n",
    "dataset_val = build_dataset(image_set=\"val\", args=args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2270d00-3035-4a7c-ba32-daacbee2669e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataset_label_num_lists(dataset):\n",
    "    label_nums = []\n",
    "    for i in range(len(dataset)):\n",
    "        _, target = dataset[i]\n",
    "        label_nums.append(target['labels'].shape[0])\n",
    "    return label_nums\n",
    "\n",
    "def run_one_random_sample_risk_estimator_for_image_based(true_losses, label_nums, seed, samples_num):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    perm = np.random.permutation(len(true_losses))\n",
    "    sampled_true_losses = []\n",
    "    count_label_num = 0\n",
    "    for i in range(perm.shape[0]):\n",
    "        if count_label_num >= samples_num:\n",
    "            break\n",
    "        sampled_true_losses.append(true_losses[perm[i]])\n",
    "        count_label_num += label_nums[perm[i]]\n",
    "    sampled_true_losses = np.array(sampled_true_losses)\n",
    "    return sampled_true_losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5d9617e-6df9-474a-8ec2-16d348f2ddf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_nums = dataset_label_num_lists(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97e31530-7741-41f8-99f3-3617f2fb3315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "box_labels_nums = 36335\n",
    "sample_size_precentage = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "sample_size_set = (np.array(sample_size_precentage) * box_labels_nums).astype(int).tolist()\n",
    "file_path = result_json_path + \"random_sample_image_level_loss_R50_31_10_runs.json\"\n",
    "json_object = {}\n",
    "for sample_size in sample_size_set:\n",
    "    for seed in random_seed_set:\n",
    "        result = {\"active_test_type\": \"random sample image level loss\", \"sample_size\": sample_size}\n",
    "        loss_risk = run_one_random_sample_risk_estimator_for_image_based(test_Y, label_nums, seed, sample_size)\n",
    "        result[\"loss\"] = loss_risk\n",
    "        json_object[len(json_object)] = result\n",
    "with open(file_path, \"w\") as outfile:\n",
    "    json.dump(json_object, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5991ee-e9fc-478a-a48a-1dca5412d91c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
