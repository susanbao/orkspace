{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a43f0d0-2e5a-4965-8102-b3223c9aecbe",
   "metadata": {},
   "source": [
    "# Demo on active testing from paper\n",
    "Active Testing: Sample–Efficient Model Evaluation\n",
    "\n",
    "Active Surrogate Estimators: An Active Learning Approach to Label–Efficient Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61163ae3-dd93-4034-9114-e4ae9c61551d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch, json\n",
    "import numpy as np\n",
    "\n",
    "from main import build_model_main\n",
    "from util.slconfig import SLConfig\n",
    "from datasets import build_dataset\n",
    "from util.visualizer import COCOVisualizer\n",
    "from util import box_ops\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91a39da7-eafe-4d24-a4d4-0a4e8a747d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_path = \"./results/deep_ensemble/\"\n",
    "consider_model_results = {\"DINO_0011_4scale.pkl\", \"DINO_0011_5scale.pkl\", \"DINO_0023_4scale.pkl\", \"DINO_0022_5scale.pkl\", \"DINO_0033_4scale.pkl\", \"DINO_0031_5scale.pkl\"}\n",
    "ego_model_index = 5\n",
    "model_nums = len(consider_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3188a666-78f5-478b-bbb7-60e7d90b71bb",
   "metadata": {},
   "source": [
    "## Load model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e0d6f44-4e60-4672-9003-1e5619362cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ['pred_boxes', 'pred_logits', 'scores', 'labels', 'boxes']\n",
    "deep_ensemble_results = []\n",
    "for path in consider_model_results:\n",
    "    temp_path = result_path + path\n",
    "    with open(temp_path, \"rb\") as outfile:\n",
    "         deep_ensemble_results.append(pickle.load(outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f347456-ff77-4ab6-a3e9-fb5d41e34479",
   "metadata": {},
   "source": [
    "## Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f19a00-acb5-4aff-8f66-3f32f13df41f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_aug_params: {\n",
      "  \"scales\": [\n",
      "    480,\n",
      "    512,\n",
      "    544,\n",
      "    576,\n",
      "    608,\n",
      "    640,\n",
      "    672,\n",
      "    704,\n",
      "    736,\n",
      "    768,\n",
      "    800\n",
      "  ],\n",
      "  \"max_size\": 1333,\n",
      "  \"scales2_resize\": [\n",
      "    400,\n",
      "    500,\n",
      "    600\n",
      "  ],\n",
      "  \"scales2_crop\": [\n",
      "    384,\n",
      "    600\n",
      "  ]\n",
      "}\n",
      "loading annotations into memory...\n",
      "Done (t=0.49s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "scale_config = \"5scale\"\n",
    "model_config_path = \"config/DINO/DINO_\" + scale_config + \".py\" # change the path of the model config file\n",
    "args = SLConfig.fromfile(model_config_path) \n",
    "args.device = 'cuda' \n",
    "args.dataset_file = 'coco'\n",
    "args.coco_path = \"../coco/\" # the path of coco\n",
    "args.fix_size = False\n",
    "dataset_val = build_dataset(image_set='val', args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023448a6-871b-46a0-8b51-8a2ff89c80c2",
   "metadata": {},
   "source": [
    "## Model results postprocess\n",
    "Include: remove prediction with low score, prediction matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67ad69ae-39fa-463a-9eda-13e3362abca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output_dict = ['pred_boxes', 'pred_logits', 'scores', 'labels', 'boxes']\n",
    "score_threshold = 0\n",
    "max_num_select = 300\n",
    "pro_results = copy.deepcopy(deep_ensemble_results)\n",
    "for agent in range(model_nums):\n",
    "    for img_idx in range(len(pro_results[agent])):\n",
    "        pred_logits = pro_results[agent][img_idx]['pred_logits']\n",
    "        pred_boxes = pro_results[agent][img_idx]['pred_boxes']\n",
    "        if pred_logits is None:\n",
    "            continue\n",
    "        # only consider prediction with score larger than score_threshold\n",
    "        select_mask = pred_logits > score_threshold\n",
    "        select_idx_all = np.reshape(select_mask, -1).nonzero()[0]\n",
    "        select_idx = select_idx_all // pred_logits.shape[2]\n",
    "        assert len(select_idx) <= max_num_select\n",
    "        if len(select_idx) <= 0:\n",
    "            pro_results[agent][img_idx]['pred_logits']  = None\n",
    "            pro_results[agent][img_idx]['lables']  = None\n",
    "            pro_results[agent][img_idx]['scores']  = None\n",
    "            pro_results[agent][img_idx]['pred_boxes']  = None\n",
    "            continue\n",
    "        lables = select_idx_all % pred_logits.shape[2]\n",
    "        scores = pred_logits[select_mask]\n",
    "        pred_boxes = pred_boxes[:, select_idx]\n",
    "        pred_logits = pred_logits[:, select_idx]\n",
    "        pro_results[agent][img_idx]['pred_logits'] = torch.from_numpy(pred_logits)\n",
    "        pro_results[agent][img_idx]['lables'] = torch.from_numpy(lables)\n",
    "        pro_results[agent][img_idx]['scores'] = torch.from_numpy(scores)\n",
    "        pro_results[agent][img_idx]['pred_boxes'] = torch.from_numpy(pred_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b1afab6-76cd-40e3-9619-2d5fb118d1da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 9, 4]),\n",
       " torch.Size([1, 9, 91]),\n",
       " torch.Size([9]),\n",
       " torch.Size([9]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_results[0][0]['pred_boxes'].shape, pro_results[0][0]['pred_logits'].shape, pro_results[0][0]['lables'].shape, pro_results[0][0]['scores'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "97f2a164-cd20-443e-b075-3366f3161b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from util.box_ops import box_cxcywh_to_xyxy, generalized_box_iou\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "def hungarian_matching(outputs, targets, cost_class = 2.0, cost_bbox = 5.0, cost_giou = 2.0, focal_alpha = 0.25):\n",
    "    \"\"\" Performs the matching\n",
    "    Params:\n",
    "        outputs/targets: This is a dict that contains at least these entries:\n",
    "             \"pred_logits\": Tensor of dim [batch_size, num_queries, num_classes] with the classification logits\n",
    "             \"pred_boxes\": Tensor of dim [batch_size, num_queries, 4] with the predicted box coordinates\n",
    "             \"lables\": Tensor of dim [num_queries] with the label of each predicted box\n",
    "    Returns:\n",
    "        A list of size batch_size, containing tuples of (index_i, index_j) where:\n",
    "            - index_i is the indices of the selected predictions (in order)\n",
    "            - index_j is the indices of the corresponding selected targets (in order with high priority)\n",
    "        For each batch element, it holds:\n",
    "            len(index_i) = len(index_j) = min(num_queries, num_target_boxes)\n",
    "    \"\"\"\n",
    "    if outputs is None or targets is None or outputs[\"pred_logits\"] is None or targets[\"pred_logits\"] is None:\n",
    "        return []\n",
    "    assert outputs[\"pred_logits\"].shape[0] == targets[\"pred_logits\"].shape[0]\n",
    "    bs, num_queries = outputs[\"pred_logits\"].shape[:2]\n",
    "    \n",
    "    # We flatten to compute the cost matrices in a batch\n",
    "    out_prob = outputs[\"pred_logits\"].flatten(0, 1).sigmoid()  # [batch_size * num_queries, num_classes]\n",
    "    out_bbox = outputs[\"pred_boxes\"].flatten(0, 1)  # [batch_size * num_queries, 4]\n",
    "    \n",
    "    tgt_ids = targets[\"lables\"]\n",
    "    tgt_bbox = targets[\"pred_boxes\"].flatten(0, 1)\n",
    "    \n",
    "    # Compute the classification cost.\n",
    "    alpha = focal_alpha\n",
    "    gamma = 2.0\n",
    "    neg_cost_class = (1 - alpha) * (out_prob ** gamma) * (-(1 - out_prob + 1e-8).log())\n",
    "    pos_cost_class = alpha * ((1 - out_prob) ** gamma) * (-(out_prob + 1e-8).log())\n",
    "    cost_class = pos_cost_class[:, tgt_ids] - neg_cost_class[:, tgt_ids]\n",
    "    \n",
    "    # Compute the L1 cost between boxes\n",
    "    cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)\n",
    "    \n",
    "    # Compute the giou cost betwen boxes            \n",
    "    cost_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_bbox), box_cxcywh_to_xyxy(tgt_bbox))\n",
    "    \n",
    "    # Final cost matrix\n",
    "    C = cost_bbox * cost_bbox + cost_class * cost_class + cost_giou * cost_giou\n",
    "    C = C.view(bs, num_queries, -1)\n",
    "    \n",
    "    num_target_boxes = targets[\"pred_logits\"].shape[1]\n",
    "    indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(num_target_boxes, -1))]\n",
    "    indices = [indices[0][0][np.argsort(indices[0][1])], np.sort(indices[0][1])]\n",
    "    return [torch.as_tensor(indices[0], dtype=torch.int64), torch.as_tensor(indices[1], dtype=torch.int64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2fa419e5-9dd0-4b9d-ad26-bde7559fb4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([2, 6, 0, 4, 1, 3, 5, 8, 7]), tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = hungarian_matching(pro_results[0][0], pro_results[3][0])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4194f311-f524-433d-aa03-42a2dda1c26c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for img_idx in range(len(pro_results[agent])):\n",
    "    for agent in range(model_nums):\n",
    "        if agent == ego_model_index:\n",
    "            continue\n",
    "        match_indices = hungarian_matching(pro_results[agent][img_idx], pro_results[ego_model_index][img_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa5c9a-af72-4ca4-b834-9523460dbdae",
   "metadata": {},
   "source": [
    "## Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966ab81-82b6-4012-a976-4fa7e806ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML Active testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a82f6513-146f-4b51-b84e-94c1e0fc1023",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 900, 91)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_ensemble_results[0][0]['pred_logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f8537ba-d61f-42c9-b120-99e3d6b7975e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 900, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_ensemble_results[0][0]['pred_boxes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24a891c1-7cdd-4472-9112-fe4ab18b9820",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_ensemble_results[0][0]['scores'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fc0f7a2-0376-40b9-9753-4742cf8bbf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_ensemble_results[0][0]['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f57bbe30-07f4-4afc-826e-99a184d880af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_ensemble_results[0][0]['boxes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd5fda9e-53f9-4506-afd7-7f2b9343f5b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boxes', 'labels', 'image_id', 'area', 'iscrowd', 'orig_size', 'size'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val[0][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d641a17f-d9a8-4579-a7ed-d2f322ad1cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3896, 0.4161, 0.0386, 0.1631],\n",
       "        [0.1276, 0.5052, 0.2333, 0.2227],\n",
       "        [0.9342, 0.5835, 0.1271, 0.1848],\n",
       "        [0.6047, 0.6325, 0.0875, 0.2414],\n",
       "        [0.5025, 0.6273, 0.0966, 0.2312],\n",
       "        [0.6692, 0.6190, 0.0471, 0.1910],\n",
       "        [0.5128, 0.5283, 0.0337, 0.0272],\n",
       "        [0.6864, 0.5320, 0.0829, 0.3240],\n",
       "        [0.6125, 0.4462, 0.0236, 0.0839],\n",
       "        [0.8119, 0.5017, 0.0230, 0.0375],\n",
       "        [0.7863, 0.5364, 0.0317, 0.2542],\n",
       "        [0.9562, 0.7717, 0.0224, 0.1073],\n",
       "        [0.9682, 0.7781, 0.0201, 0.1090],\n",
       "        [0.7106, 0.3100, 0.0218, 0.0514],\n",
       "        [0.8866, 0.8316, 0.0573, 0.2105],\n",
       "        [0.5569, 0.5167, 0.0178, 0.0529],\n",
       "        [0.6517, 0.5288, 0.0150, 0.0294],\n",
       "        [0.3880, 0.4784, 0.0222, 0.0414],\n",
       "        [0.5338, 0.4879, 0.0152, 0.0393],\n",
       "        [0.6000, 0.6471, 0.1962, 0.2088]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val[0][1]['boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "522ae0cf-fd2d-459d-a141-58322acbd45b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = deep_ensemble_results[0][0]\n",
    "target_sizes = torch.Tensor([[1.0, 1.0]])\n",
    "out_logits, out_bbox = torch.Tensor(outputs['pred_logits']), torch.Tensor(outputs['pred_boxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7158d6eb-d3d7-413f-88d1-a02c86137457",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  if sys.path[0] == \"\":\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'unbind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16211/216271073.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# and from relative [0, 1] to absolute [0, height] coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mimg_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mscale_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_h\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale_fct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'unbind'"
     ]
    }
   ],
   "source": [
    "num_select = 300\n",
    "nms_iou_threshold = -1\n",
    "not_to_xyxy = False\n",
    "test = True\n",
    "assert len(out_logits) == len(target_sizes)\n",
    "\n",
    "prob = out_logits.sigmoid()\n",
    "topk_values, topk_indexes = torch.topk(prob.view(out_logits.shape[0], -1), num_select, dim=1)\n",
    "scores = topk_values\n",
    "topk_boxes = topk_indexes // out_logits.shape[2]\n",
    "labels = topk_indexes % out_logits.shape[2]\n",
    "if not_to_xyxy:\n",
    "    boxes = out_bbox\n",
    "else:\n",
    "    boxes = box_ops.box_cxcywh_to_xyxy(out_bbox)\n",
    "\n",
    "if test:\n",
    "    assert not not_to_xyxy\n",
    "    boxes[:,:,2:] = boxes[:,:,2:] - boxes[:,:,:2]\n",
    "boxes = torch.gather(boxes, 1, topk_boxes.unsqueeze(-1).repeat(1,1,4))\n",
    "\n",
    "# and from relative [0, 1] to absolute [0, height] coordinates\n",
    "img_h, img_w = target_sizes.unbind(1)\n",
    "scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1)\n",
    "boxes = boxes * scale_fct[:, None, :]\n",
    "\n",
    "if nms_iou_threshold > 0:\n",
    "    item_indices = [nms(b, s, iou_threshold=nms_iou_threshold) for b,s in zip(boxes, scores)]\n",
    "\n",
    "    results = [{'scores': s[i], 'labels': l[i], 'boxes': b[i]} for s, l, b, i in zip(scores, labels, boxes, item_indices)]\n",
    "else:\n",
    "    results = [{'scores': s, 'labels': l, 'boxes': b} for s, l, b in zip(scores, labels, boxes)]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7033e6f3-2b06-4ff0-abba-066d8d078194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 81900])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.view(out_logits.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a8d46f9-4cfa-492d-82e8-7641f99b6ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 900, 91)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['pred_logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8edd0bd5-0593-4191-89b3-7c549d1b50f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81900"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "900*91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843d19d4-7fd7-4c74-af52-f6a91d4465ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
