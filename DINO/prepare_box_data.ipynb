{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42e50d2c-ddfd-4eb0-9b17-487b096e2027",
   "metadata": {},
   "source": [
    "# Prepare data for box-level loss estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0fc2125-eb18-44ff-928c-2f976d4e68fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from datasets import build_dataset\n",
    "from util.slconfig import SLConfig\n",
    "from util.box_ops import box_cxcywh_to_xyxy, generalized_box_iou\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d8033f0-5454-472f-b39a-13991be11ece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_one_image_results(path):\n",
    "    with open(path, \"r\") as outfile:\n",
    "        data = json.load(outfile)\n",
    "    return data\n",
    "\n",
    "def write_one_results(path, json_data):\n",
    "    with open(path, \"w\") as outfile:\n",
    "        json.dump(json_data, outfile)\n",
    "        \n",
    "def transform_tensor_to_list(l):\n",
    "    return l.cpu().tolist()\n",
    "\n",
    "def transform_tensors_to_list(l):\n",
    "    if torch.is_tensor(l):\n",
    "        return transform_tensor_to_list(l)\n",
    "    if isinstance(l, list):\n",
    "        r = []\n",
    "        for i in l:\n",
    "            r.append(transform_tensors_to_list(i))\n",
    "        return r\n",
    "    if isinstance(l, dict):\n",
    "        r = {}\n",
    "        for k,v in l.items():\n",
    "            r[k] = transform_tensors_to_list(v)\n",
    "        return r\n",
    "    return l\n",
    "\n",
    "def generate_one_image_results(path):\n",
    "    results = read_one_image_results(path)\n",
    "    pred_logits = torch.FloatTensor(results['input']['pred_logits']).squeeze(axis=0)\n",
    "    pred_boxes = torch.FloatTensor(results['input']['pred_boxes']).squeeze(axis=0)\n",
    "    prob = pred_logits.sigmoid()\n",
    "    select_mask = prob > score_threshold\n",
    "    if select_mask.sum() == 0:\n",
    "        loc = prob.argmax()\n",
    "        x_loc = torch.div(loc, prob.shape[1], rounding_mode='floor')\n",
    "        y_loc = loc % prob.shape[1]\n",
    "        select_mask[x_loc, y_loc] = 1\n",
    "    score = prob[select_mask]\n",
    "    selected_index = torch.div(torch.nonzero(select_mask.reshape(-1)),prob.shape[1], rounding_mode='floor').squeeze(axis=1)\n",
    "    labels = torch.nonzero(select_mask.reshape(-1)) % prob.shape[1]\n",
    "    out_logits = pred_logits[selected_index]\n",
    "    out_boxes = pred_boxes[selected_index]\n",
    "    return selected_index, score, labels, out_logits, out_boxes\n",
    "\n",
    "def hungarian_matching(out_logits, out_boxes, targets, cost_class = 2.0, cost_bbox = 5.0, cost_giou = 2.0, focal_alpha = 0.25):\n",
    "    \"\"\" Performs the matching\n",
    "    \"\"\"\n",
    "    if targets[\"boxes\"] is None or targets[\"labels\"].shape[0] == 0:\n",
    "        return None\n",
    "    \n",
    "    # We flatten to compute the cost matrices in a batch\n",
    "    num_queries = out_logits.shape[0]\n",
    "    out_prob = out_logits.sigmoid()  # [num_queries, num_classes]\n",
    "    \n",
    "    tgt_ids = targets[\"labels\"]\n",
    "    tgt_bbox = targets[\"boxes\"]\n",
    "    \n",
    "    # Compute the classification cost.\n",
    "    alpha = focal_alpha\n",
    "    gamma = 2.0\n",
    "    neg_cost_class = (1 - alpha) * (out_prob ** gamma) * (-(1 - out_prob + 1e-8).log())\n",
    "    pos_cost_class = alpha * ((1 - out_prob) ** gamma) * (-(out_prob + 1e-8).log())\n",
    "    cost_class = pos_cost_class[:, tgt_ids] - neg_cost_class[:, tgt_ids]\n",
    "    \n",
    "    # Compute the L1 cost between boxes\n",
    "    cost_bbox = torch.cdist(out_boxes, tgt_bbox, p=1)\n",
    "    \n",
    "    # Compute the giou cost betwen boxes            \n",
    "    cost_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_boxes), box_cxcywh_to_xyxy(tgt_bbox))\n",
    "    \n",
    "    # Final cost matrix\n",
    "    C = cost_bbox * cost_bbox + cost_class * cost_class + cost_giou * cost_giou\n",
    "    C = C.view(num_queries, -1)\n",
    "    return torch.argmin(C, axis=1)\n",
    "\n",
    "\n",
    "def sigmoid_focal_loss(inputs, targets, alpha: float = 0.25, gamma: float = 2):\n",
    "    \"\"\"\n",
    "    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n",
    "    Args:\n",
    "        inputs: A float tensor of arbitrary shape.\n",
    "                The predictions for each example.\n",
    "        targets: A float tensor with the same shape as inputs. Stores the binary\n",
    "                 classification label for each element in inputs\n",
    "                (0 for the negative class and 1 for the positive class).\n",
    "        alpha: (optional) Weighting factor in range (0,1) to balance\n",
    "                positive vs negative examples. Default = -1 (no weighting).\n",
    "        gamma: Exponent of the modulating factor (1 - p_t) to\n",
    "               balance easy vs hard examples.\n",
    "    Returns:\n",
    "        Loss tensor\n",
    "    \"\"\"\n",
    "    prob = inputs.sigmoid()\n",
    "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "    p_t = prob * targets + (1 - prob) * (1 - targets)\n",
    "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
    "\n",
    "    if alpha >= 0:\n",
    "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "        loss = alpha_t * loss\n",
    "    return loss\n",
    "\n",
    "def compute_loss(out_logits, out_boxes, targets, matched_target_indexes, cls_loss_coef = 1.0, bbox_loss_coef = 5.0, giou_loss_coef = 2.0):\n",
    "    if matched_target_indexes == None:\n",
    "        target_classes_onehot = torch.zeros([out_logits.shape[0], out_logits.shape[1]],dtype=out_logits.dtype, layout=out_logits.layout, \n",
    "                                        device=out_logits.device)\n",
    "        loss_ce = sigmoid_focal_loss(out_logits, target_classes_onehot)\n",
    "        loss_ce = loss_ce.sum(axis=1)\n",
    "        loss = loss_ce * cls_loss_coef\n",
    "        return loss, loss_ce, torch.zeros(loss.shape), torch.zeros(loss.shape)\n",
    "    cls_loss_coef = 1.0\n",
    "    bbox_loss_coef = 5.0\n",
    "    giou_loss_coef = 2.0\n",
    "    target_boxes = targets['boxes'][matched_target_indexes]\n",
    "    loss_bbox = F.l1_loss(out_boxes, target_boxes, reduction='none') # [num_queries, 4]\n",
    "    loss_bbox = loss_bbox.mean(axis=1) # [num_queries]\n",
    "    loss_giou = 1 - torch.diag(generalized_box_iou(box_cxcywh_to_xyxy(out_boxes),\n",
    "                box_cxcywh_to_xyxy(target_boxes))) # [num_queries]\n",
    "    target_classes_onehot = torch.zeros([out_logits.shape[0], out_logits.shape[1]],dtype=out_logits.dtype, layout=out_logits.layout, \n",
    "                                        device=out_logits.device)\n",
    "    target_labels = targets['labels'][matched_target_indexes]\n",
    "    target_classes_onehot.scatter_(1, target_labels.unsqueeze(-1), 1)\n",
    "    loss_ce = sigmoid_focal_loss(out_logits, target_classes_onehot)\n",
    "    loss_ce = loss_ce.sum(axis=1)\n",
    "    loss = loss_ce * cls_loss_coef + loss_bbox * bbox_loss_coef + loss_giou * giou_loss_coef\n",
    "    return loss, loss_ce, loss_bbox, loss_giou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa0f6a-3c65-417c-900d-b7c2f1629f4e",
   "metadata": {},
   "source": [
    "## parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6724c90-da0b-4a44-a602-425320c2af67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = \"train\"\n",
    "data_path = \"./data/5_scale_31/\" + split + \"/data/\"\n",
    "store_path = \"./data/5_scale_31/\" + split + \"/box_annotation/\"\n",
    "image_nums = 5000\n",
    "score_threshold = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7069d20a-dd61-43bd-9a9c-ab2f762fa70f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_aug_params: {\n",
      "  \"scales\": [\n",
      "    480,\n",
      "    512,\n",
      "    544,\n",
      "    576,\n",
      "    608,\n",
      "    640,\n",
      "    672,\n",
      "    704,\n",
      "    736,\n",
      "    768,\n",
      "    800\n",
      "  ],\n",
      "  \"max_size\": 1333,\n",
      "  \"scales2_resize\": [\n",
      "    400,\n",
      "    500,\n",
      "    600\n",
      "  ],\n",
      "  \"scales2_crop\": [\n",
      "    384,\n",
      "    600\n",
      "  ]\n",
      "}\n",
      "loading annotations into memory...\n",
      "Done (t=15.29s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "model_config_path = \"config/DINO/DINO_5scale.py\"\n",
    "args = SLConfig.fromfile(model_config_path) \n",
    "args.dataset_file = 'coco'\n",
    "args.coco_path = \"../coco/\" # the path of coco\n",
    "args.fix_size = False\n",
    "\n",
    "dataset_val = build_dataset(image_set=split, args=args)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e180fce0-cc6d-46d5-af10-db00d5a0a9ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete 1/118287\n",
      "Complete 1001/118287\n",
      "Complete 2001/118287\n",
      "Complete 3001/118287\n",
      "Complete 4001/118287\n",
      "Complete 5001/118287\n",
      "Complete 6001/118287\n",
      "Complete 7001/118287\n",
      "Complete 8001/118287\n",
      "Complete 9001/118287\n",
      "Complete 10001/118287\n",
      "Complete 11001/118287\n",
      "Complete 12001/118287\n",
      "Complete 13001/118287\n",
      "Complete 14001/118287\n",
      "Complete 15001/118287\n",
      "Complete 16001/118287\n",
      "Complete 17001/118287\n",
      "Complete 18001/118287\n",
      "Complete 19001/118287\n",
      "Complete 20001/118287\n",
      "Complete 21001/118287\n",
      "Complete 22001/118287\n"
     ]
    }
   ],
   "source": [
    "image_nums = len(dataset_val)\n",
    "for image_idx in range(image_nums):\n",
    "    image_path = data_path + str(image_idx) + \".json\"\n",
    "    selected_index, score, labels, out_logits, out_boxes = generate_one_image_results(image_path)\n",
    "    _, targets = dataset_val[image_idx]\n",
    "    matched_target_indexes = hungarian_matching(out_logits, out_boxes, targets)\n",
    "    loss, loss_ce, loss_bbox, loss_giou = compute_loss(out_logits, out_boxes, targets, matched_target_indexes)\n",
    "    json_object = {'matched_target_indexes': matched_target_indexes, 'out_labels': labels.squeeze(axis=1), 'loss': loss, \n",
    "               'loss_ce': loss_ce, 'loss_bbox': loss_bbox, 'loss_giou': loss_giou}\n",
    "    image_store_path = store_path + str(image_idx) + \".json\"\n",
    "    json_object = transform_tensors_to_list(json_object)\n",
    "    write_one_results(image_store_path, json_object)\n",
    "    if image_idx % 1000 == 0:\n",
    "        print(f\"Complete {image_idx+1}/{image_nums}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cdd8388-e0b7-49c1-a8a4-f158473cf88b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5bc5bd5-e805-4b03-9daf-6d4c7e3d4565",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118287"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d146a54f-3857-4918-8664-2aa4942388ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f8ce7eb-203e-4c42-8ed9-2de6536ea421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba4886-1378-4342-9cba-da04c42fed87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
